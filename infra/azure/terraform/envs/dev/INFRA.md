ğŸŒ INFRA.md â€“ Infraestrutura do Projeto Intelligent Trading Bot

Documento oficial da infraestrutura do projeto.
Mantido no branch dev.
Objetivo: garantir reprodutibilidade, previsibilidade e continuidade operacional.

---

ğŸ“Œ 1. Arquitetura Geral

A infraestrutura atual opera no modelo:

Local Dev â†’ Azure Dev (ACI + Storage) â†’ Staging Shadow Mode â†’ Futuro Prod Live Trading

A plataforma usa:
- Azure Storage Account para datasets versionados (Parquet, CSV, modelos).
- Azure Container Registry (ACR) para imagens Docker do bot e pipelines.
- Azure Container Instances (ACI) para rodar pipelines offline (treino, merge, labels, predict).
- Recovery Services Vault para backup diÃ¡rio dos dados crÃ­ticos.
- Terraform para provisionamento da infraestrutura base.

---

ğŸ—‚ï¸ 2. Recursos Azure

### 2.1 Resource Group (RG)

**Nome:** `rg-itb-dev`  
**FunÃ§Ã£o:** Agrupar todos os recursos do ambiente de desenvolvimento e staging.

---

### 2.2 Storage Account

**Nome:** `stitbdev`  
**Tipo:** StorageV2  
**LocalizaÃ§Ã£o:** eastus  

**Usos:**
- Armazenamento de datasets versionados (1m, 5m, 1h).
- Armazenamento dos modelos treinados.
- Armazenamento de sinais, matrizes e features.
- Fonte de dados para pipelines de treino em ACI.

**Acesso:**
- Chave primÃ¡ria habilitada  
- Public Network Access: Enabled  
- TLS 1.2  

---

### 2.3 File Shares

Estrutura atual:

| File share      | PropÃ³sito                     |
|-----------------|-------------------------------|
| data-itb-1m     | Dataset BTCUSDT 1m            |
| data-itb-5m     | Dataset BTCUSDT 5m            |
| data-itb-1h     | Dataset BTCUSDT 1h            |

PadrÃ£o interno:

```
<share-name>/
  BTCUSDT/
    vYYYY-MM-DD/
      klines.parquet
      features.csv
      matrix.csv
      predictions.csv
      predictions.txt
      signals.csv
      signal_models.txt
      Archive.zip
      MODELS/
        *.pickle
        *.scaler
```

---

### 2.4 Azure Container Registry (ACR)

**Nome:** `itbacr`  
**Login server:** `itbacr.azurecr.io`  
**SKU:** Basic  
**Admin user:** Enabled  

**Usos:**
- Armazenar imagens Docker para:
  - Pipelines dev
  - Merge/Labels/Predict
  - Staging
  - Futuro Prod

**ConvenÃ§Ã£o de tags:**

```
itbacr.azurecr.io/itb-bot:<branch>-<commit>
itbacr.azurecr.io/itb-bot:dev-latest
itbacr.azurecr.io/itb-bot:staging-latest
```

---

### 2.5 Recovery Services Vault

**Nome:** `vault697`  
**LocalizaÃ§Ã£o:** `eastus`

**PolÃ­tica:**
- FrequÃªncia: diÃ¡ria
- HorÃ¡rio: 19:30 UTC
- RetenÃ§Ã£o: 30 dias

**File shares protegidos:**
- `data-itb-1m`
- `data-itb-5m`
- `data-itb-1h`

---

ğŸ› ï¸ 3. Provisionamento (Terraform)

Local dos arquivos:

```
infra/azure/terraform/envs/dev
```

Comandos:

```
terraform init
terraform plan
terraform apply
```

Recursos gerenciados:
- Resource Group  
- Storage Account  
- File Shares (1m, 5m, 1h)  
- Container Registry (importado)

âš ï¸ O Recovery Services Vault ainda nÃ£o estÃ¡ sob Terraform.

---

ğŸš€ 4. Pipelines CI/CD (GitHub Actions)

Pipelines principais:

- `dev-aci-pipeline-1m.yml` â€“ roda merge â†’ features â†’ labels â†’ train â†’ predict â†’ signals  
- `merge-only-aci.yml`  
- `labels_new-only-aci.yml`  
- `train-only-aci.yml`  
- `predict-signals-only-aci.yml`  
- `simulate-only.yml`  

Pipelines separados facilitam debug e testes A/B.

---

ğŸ“Š 5. Versionamento de Datasets

Parquets e artefatos sÃ£o versionados seguindo:

```
vYYYY-MM-DD
```

Exemplo:

```
data-itb-1m/BTCUSDT/v2025-12-05/
```

Isso garante:
- Reprodutibilidade  
- ComparaÃ§Ã£o entre versÃµes  
- Possibilidade de treinar modelos com datasets histÃ³ricos precisos  

---

ğŸ“¦ 6. Upload de datasets (Makefile + Scripts)

Scripts:

```
tools/upload_1m_parquet.sh
tools/upload_5m_parquet.sh
tools/upload_1h_parquet.sh
```

Makefile:

```
make upload-1m
make upload-5m
make upload-1h
```

Os scripts:
- Criam a pasta versionada
- Fazem upload via `az storage file upload-batch`
- Exibem os links dos arquivos enviados

---

ğŸ³ 7. Docker

Dockerfile:

- Base Python 3.11 Slim
- Instala dependÃªncias
- Copia scripts e mÃ³dulos

Build local:

```
docker build -t itb-bot:local .
```

Push para ACR:

```
docker tag itb-bot:local itbacr.azurecr.io/itb-bot:dev-latest
docker push itbacr.azurecr.io/itb-bot:dev-latest
```

---

ğŸ§ª 8. Ambientes

### DEV
- Rodado localmente ou em ACI
- Usado para gerar parquets, treinar modelos, ajustar configs

### STAGING (shadow mode)
Executado local:

```
ENABLE_LIVE_TRADING=true python -m service.server -c configs/btcusdt_1m_staging_v2.jsonc
ENABLE_LIVE_TRADING=true python -m service.server -c configs/btcusdt_5m_staging_v2.jsonc
```

Objetivo:
- Emitir BUY/SELL reais
- NÃ£o executar trades
- Gerar logs analisÃ¡veis

### PROD (futuro)
- Config dedicado
- ExecuÃ§Ã£o em ACI ou Azure Container Apps
- Observabilidade completa

---

ğŸ“ˆ 9. Logs & Analytics

Estrutura:

```
logs/raw/
logs/analytics/
logs/server_1m_*.log
logs/server_5m_*.log
```

Scripts:

```
parse_staging_logs.py
analyze_btcusdt_1m.py
analyze_btcusdt_5m.py
analyze_btcusdt_1h.py
```

Resultados:
- JSON automÃ¡tico em `logs/analytics/`
- Arquivos `.result.txt` para leitura humana

---

ğŸ§  10. Roadmap Infra

### âœ”ï¸ JÃ¡ feito
- Backup diÃ¡rio
- Versionamento completo dos datasets
- Upload automatizado
- Pipelines dev rodando em ACI
- Staging shadow mode

### ğŸ”œ PrÃ³ximos passos
- Criar banco PostgreSQL para armazenar:
  - PnL  
  - Sinais  
  - MÃ©tricas de modelo  
- Mover Recovery Vault para Terraform
- Criar ambiente PROD

---

ğŸ§© 11. Comandos Ãºteis

Login:

```
az login
az account set --subscription "Azure subscription 1"
```

Upload:

```
make upload-1m VERSION=v2025-12-05
```

Rodar staging:

```
make staging-1m
make staging-5m
```

Pipeline dev:

```
make dev-1m
make dev-5m
```

---

âœ”ï¸ Documento finalizado.

Pronto para auditoria, evoluÃ§Ã£o e colaboraÃ§Ã£o profissional.