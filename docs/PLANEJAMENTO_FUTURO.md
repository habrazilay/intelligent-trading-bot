# Planejamento Futuro: Arquitetura de Dados & Logging

**Status:** Planejamento/Discuss√£o
**Prioridade:** M√©dia (ap√≥s teste orderflow)
**Timeline:** Q1 2025

---

## üóÇÔ∏è Refatora√ß√£o da Estrutura de Dados

### Estrutura Atual (Sub√≥tima)

```
DATA_ITB_5m/
‚îî‚îÄ‚îÄ BTCUSDT/
    ‚îú‚îÄ‚îÄ klines.parquet
    ‚îú‚îÄ‚îÄ data.csv
    ‚îú‚îÄ‚îÄ features_aggressive.csv
    ‚îú‚îÄ‚îÄ matrix_aggressive.csv
    ‚îú‚îÄ‚îÄ predictions_aggressive.csv
    ‚îú‚îÄ‚îÄ signals_aggressive.csv
    ‚îî‚îÄ‚îÄ MODELS_AGGRESSIVE_V1/
        ‚îú‚îÄ‚îÄ high_040_4_lgbm.pkl
        ‚îî‚îÄ‚îÄ low_040_4_lgbm.pkl
```

**Problemas:**
- ‚ùå `MODELS_AGGRESSIVE_V1` enterrada dentro da pasta do s√≠mbolo
- ‚ùå Dif√≠cil comparar modelos entre s√≠mbolos
- ‚ùå Sem separa√ß√£o clara de responsabilidades
- ‚ùå Nome da variante (`aggressive`) espalhado nos nomes dos arquivos

---

### Estrutura Proposta (Melhor)

```
data/
‚îú‚îÄ‚îÄ {symbol}/
‚îÇ   ‚îú‚îÄ‚îÄ {freq}/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ klines.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ features.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labeled/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ matrix.csv
‚îÇ   ‚îî‚îÄ‚îÄ orderbook/
‚îÇ       ‚îî‚îÄ‚îÄ snapshots_*.parquet
‚îÇ
‚îî‚îÄ‚îÄ models/
    ‚îú‚îÄ‚îÄ {symbol}/
    ‚îÇ   ‚îú‚îÄ‚îÄ {freq}/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {variant}/          # aggressive, conservative, orderflow
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {algo}/          # lgbm, logreg, automl
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {label}/     # high_040_4, low_040_4
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.pkl
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata.json
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
```

**Exemplo:**
```
data/
‚îú‚îÄ‚îÄ BTCUSDT/
‚îÇ   ‚îú‚îÄ‚îÄ 5m/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw/klines.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/features.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labeled/matrix.csv
‚îÇ   ‚îî‚îÄ‚îÄ orderbook/
‚îÇ       ‚îî‚îÄ‚îÄ snapshots_20251210.parquet
‚îÇ
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ BTCUSDT/
        ‚îî‚îÄ‚îÄ 5m/
            ‚îú‚îÄ‚îÄ aggressive/
            ‚îÇ   ‚îî‚îÄ‚îÄ lgbm/
            ‚îÇ       ‚îú‚îÄ‚îÄ high_040_4/
            ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ model.pkl
            ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ metadata.json  # data de treino, features, hyperparams
            ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json   # win rate, sharpe, etc
            ‚îÇ       ‚îî‚îÄ‚îÄ low_040_4/
            ‚îÇ           ‚îî‚îÄ‚îÄ ...
            ‚îî‚îÄ‚îÄ orderflow/
                ‚îî‚îÄ‚îÄ automl/
                    ‚îî‚îÄ‚îÄ high_040_4/
                        ‚îî‚îÄ‚îÄ ...
```

**Benef√≠cios:**
- ‚úÖ Hierarquia clara: symbol ‚Üí freq ‚Üí variant ‚Üí algo ‚Üí label
- ‚úÖ F√°cil encontrar/comparar modelos
- ‚úÖ Separa√ß√£o: data vs models
- ‚úÖ Metadata + m√©tricas com cada modelo
- ‚úÖ Versionamento embutido (pasta = vers√£o)

---

### Estrat√©gia de Migra√ß√£o

**Quando:** Ap√≥s teste orderflow (17/dez em diante)

**Esfor√ßo:** ~1-2 dias
- Atualizar todos os scripts para usar novos caminhos
- Escrever script de migra√ß√£o (copiar antigo ‚Üí nova estrutura)
- Testar pipeline end-to-end
- Atualizar configs

**Compatibilidade retroativa:**
```python
# Adicionar resolvedor de caminho
def get_model_path(symbol, freq, variant, algo, label):
    # Tentar nova estrutura primeiro
    new_path = f"models/{symbol}/{freq}/{variant}/{algo}/{label}/model.pkl"
    if os.path.exists(new_path):
        return new_path

    # Voltar para estrutura antiga
    old_path = f"DATA_ITB_{freq}/{symbol}/MODELS_{variant.upper()}_V1/{label}_{algo}.pkl"
    return old_path
```

---

## üíæ Migra√ß√£o de Banco de Dados (BigData)

### Problema: Armazenamento Baseado em Arquivos N√£o Escala

**Abordagem atual:**
```
Arquivos CSV: 51,864 linhas √ó 35 colunas = ~12 MB
Arquivos Parquet: ~500 KB cada

Problemas:
- N√£o consegue fazer queries eficientes (precisa pandas.read_csv)
- Sem indexa√ß√£o (buscas lentas)
- Sem acesso concorrente (locks de arquivo)
- Sem agrega√ß√µes (GROUP BY, JOIN)
- Dif√≠cil analisar tend√™ncias hist√≥ricas
```

**Quando se torna cr√≠tico:**
- M√∫ltiplos s√≠mbolos (5+ s√≠mbolos √ó 3 timeframes = 15 datasets)
- Profundidade hist√≥rica (2+ anos de dados 1m = milh√µes de linhas)
- Queries em tempo real (precisam de buscas sub-segundo)
- Acesso multi-usu√°rio (dashboards, an√°lise, trading)

---

### Proposta: TimescaleDB (PostgreSQL para S√©ries Temporais)

**Por que TimescaleDB:**
- ‚úÖ Compat√≠vel com PostgreSQL (SQL familiar)
- ‚úÖ Otimizado para s√©ries temporais (particionamento autom√°tico)
- ‚úÖ Compress√£o (economia de espa√ßo 50-90%)
- ‚úÖ Agrega√ß√µes cont√≠nuas (pr√©-computar m√©tricas)
- ‚úÖ Open source + op√ß√£o self-hosted

**Design do Schema:**

```sql
-- Dados OHLCV (raw)
CREATE TABLE ohlcv (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    freq TEXT NOT NULL,
    open NUMERIC,
    high NUMERIC,
    low NUMERIC,
    close NUMERIC,
    volume NUMERIC,
    PRIMARY KEY (time, symbol, freq)
);

SELECT create_hypertable('ohlcv', 'time');

-- Features (processadas)
CREATE TABLE features (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    freq TEXT NOT NULL,
    close_sma_3 NUMERIC,
    close_rsi_14 NUMERIC,
    vol_regime INTEGER,
    -- ... todas as features
    PRIMARY KEY (time, symbol, freq)
);

SELECT create_hypertable('features', 'time');

-- Labels
CREATE TABLE labels (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    freq TEXT NOT NULL,
    high_040_4 BOOLEAN,
    low_040_4 BOOLEAN,
    -- ... todas as labels
    PRIMARY KEY (time, symbol, freq)
);

SELECT create_hypertable('labels', 'time');

-- Predictions (outputs dos modelos)
CREATE TABLE predictions (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    freq TEXT NOT NULL,
    model_name TEXT NOT NULL,      -- ex: "lgbm_aggressive"
    label TEXT NOT NULL,            -- ex: "high_040_4"
    probability NUMERIC,
    prediction BOOLEAN,
    PRIMARY KEY (time, symbol, freq, model_name, label)
);

SELECT create_hypertable('predictions', 'time');

-- Trades (executados)
CREATE TABLE trades (
    id SERIAL PRIMARY KEY,
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    side TEXT NOT NULL,            -- 'BUY' ou 'SELL'
    price NUMERIC NOT NULL,
    quantity NUMERIC NOT NULL,
    model_name TEXT,
    signal_strength NUMERIC,
    pnl NUMERIC,                   -- P&L Realizado
    status TEXT                    -- 'OPEN', 'CLOSED', 'CANCELLED'
);

CREATE INDEX ON trades (time DESC);
CREATE INDEX ON trades (symbol, time DESC);

-- M√©tricas de performance (agregadas)
CREATE MATERIALIZED VIEW daily_performance
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS day,
    symbol,
    model_name,
    COUNT(*) AS total_trades,
    SUM(CASE WHEN pnl > 0 THEN 1 ELSE 0 END)::FLOAT / COUNT(*) AS win_rate,
    SUM(pnl) AS total_pnl,
    AVG(pnl) AS avg_pnl,
    MAX(pnl) AS max_win,
    MIN(pnl) AS max_loss
FROM trades
WHERE status = 'CLOSED'
GROUP BY day, symbol, model_name;
```

**Exemplos de Queries:**

```sql
-- Obter features recentes para predi√ß√£o
SELECT * FROM features
WHERE symbol = 'BTCUSDT'
  AND freq = '5m'
  AND time >= NOW() - INTERVAL '1 hour'
ORDER BY time DESC
LIMIT 12;

-- Performance do modelo √∫ltimos 30 dias
SELECT
    symbol,
    model_name,
    win_rate,
    total_pnl,
    total_trades
FROM daily_performance
WHERE day >= NOW() - INTERVAL '30 days'
ORDER BY total_pnl DESC;

-- Comparar modelos Azure vs GCP
SELECT
    CASE
        WHEN model_name LIKE '%azure%' THEN 'Azure'
        WHEN model_name LIKE '%gcp%' THEN 'GCP'
    END AS cloud,
    AVG(win_rate) AS avg_win_rate,
    SUM(total_pnl) AS total_profit
FROM daily_performance
WHERE day >= NOW() - INTERVAL '7 days'
GROUP BY cloud;
```

---

### Migra√ß√£o de CSV ‚Üí TimescaleDB

**Fase 1: Escrita dupla (1 semana)**
```python
# Escrever tanto em CSV quanto em DB
df.to_csv('features.csv')
df.to_sql('features', engine, if_exists='append')
```

**Fase 2: Ler do DB (1 semana de testes)**
```python
# Ler do DB ao inv√©s de CSV
df = pd.read_sql(
    "SELECT * FROM features WHERE symbol = %s AND freq = %s",
    engine,
    params=('BTCUSDT', '5m')
)
```

**Fase 3: Depreciar CSV (ap√≥s 2 semanas)**
```python
# Remover escritas em CSV
# Manter CSV como backup por 1 m√™s
```

---

## üìù Arquitetura de Logging

### Estado Atual: B√°sico

```python
# Print statements simples ou logging b√°sico
logging.info("Training started")
print(f"Win rate: {win_rate}")
```

**Problemas:**
- ‚ùå Sem logs estruturados (dif√≠cil fazer parse)
- ‚ùå Logs espalhados (arquivos, stdout, stderr)
- ‚ùå Sem agrega√ß√£o centralizada
- ‚ùå Dif√≠cil buscar/filtrar
- ‚ùå Sem pol√≠tica de reten√ß√£o

---

### Proposta: Logging Estruturado + ELK Stack

**Tech Stack:**
- **Loguru** (Python): Melhor que logging stdlib
- **Elasticsearch**: Armazenar + buscar logs
- **Kibana**: Visualizar + dashboard
- **Filebeat**: Enviar logs para Elasticsearch

**Exemplo de Logging Estruturado:**

```python
from loguru import logger
import sys

# Configurar logger
logger.remove()  # Remover handler padr√£o
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="INFO",
)
logger.add(
    "logs/app_{time:YYYY-MM-DD}.log",
    rotation="1 day",
    retention="30 days",
    compression="zip",
    level="DEBUG",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} - {message}",
)

# Campos estruturados extras
logger.bind(
    symbol="BTCUSDT",
    freq="5m",
    model="lgbm_aggressive"
).info(
    "Model training completed",
    win_rate=0.58,
    sharpe=2.1,
    trades=300
)

# Output (JSON para Elasticsearch):
# {
#   "time": "2025-12-10 10:30:00",
#   "level": "INFO",
#   "message": "Model training completed",
#   "symbol": "BTCUSDT",
#   "freq": "5m",
#   "model": "lgbm_aggressive",
#   "extra": {
#     "win_rate": 0.58,
#     "sharpe": 2.1,
#     "trades": 300
#   }
# }
```

**N√≠veis de Log:**

```python
# DEBUG: Info de diagn√≥stico detalhada
logger.debug("Feature calculation", feature_name="close_sma_3", value=99500.5)

# INFO: Opera√ß√µes normais
logger.info("Pipeline step completed", step="merge", duration_sec=5.2)

# WARNING: Problemas potenciais
logger.warning("High API latency", latency_ms=1500, threshold_ms=1000)

# ERROR: Falhas que n√£o param execu√ß√£o
logger.error("Failed to fetch orderbook", symbol="SOLUSDT", error=str(e))

# CRITICAL: Falhas severas
logger.critical("Trading halted", reason="max_drawdown_exceeded", drawdown_pct=15.2)
```

---

### Setup ELK Stack (Docker)

```yaml
# docker-compose.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    volumes:
      - ./logs:/logs:ro
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
    depends_on:
      - elasticsearch

volumes:
  es-data:
```

**Config do Filebeat:**
```yaml
# filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /logs/*.log
    json.keys_under_root: true
    json.add_error_key: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "itb-logs-%{+yyyy.MM.dd}"

setup.kibana:
  host: "kibana:5601"
```

**Uso:**
```bash
# Iniciar ELK stack
docker-compose up -d

# Ver logs no Kibana
# http://localhost:5601
# Criar index pattern: itb-logs-*
# Query: symbol:"BTCUSDT" AND level:"ERROR"
```

---

### Organiza√ß√£o de Logs

**Estrutura de pastas:**
```
logs/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ app_2025-12-10.log         # Aplica√ß√£o geral
‚îÇ   ‚îî‚îÄ‚îÄ app_2025-12-11.log
‚îú‚îÄ‚îÄ trading/
‚îÇ   ‚îú‚îÄ‚îÄ trading_2025-12-10.log     # Execu√ß√£o de trades
‚îÇ   ‚îî‚îÄ‚îÄ trading_2025-12-11.log
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ training_2025-12-10.log    # Treinamento de modelos
‚îÇ   ‚îî‚îÄ‚îÄ predictions_2025-12-10.log # Predi√ß√µes
‚îú‚îÄ‚îÄ cloud/
‚îÇ   ‚îú‚îÄ‚îÄ azure_2025-12-10.log       # Opera√ß√µes Azure
‚îÇ   ‚îî‚îÄ‚îÄ gcp_2025-12-10.log         # Opera√ß√µes GCP
‚îî‚îÄ‚îÄ errors/
    ‚îî‚îÄ‚îÄ errors_2025-12-10.log      # Todos os erros (agregados)
```

**Reten√ß√£o:**
- Logs da app: 30 dias
- Logs de trading: 1 ano (compliance legal)
- Logs de modelos: 90 dias
- Logs de erro: 6 meses

---

## üîç Monitoramento & Observabilidade

### M√©tricas a Rastrear

**M√©tricas de Sistema:**
```python
# CPU, Mem√≥ria, Disco
import psutil

logger.info(
    "System metrics",
    cpu_percent=psutil.cpu_percent(),
    memory_percent=psutil.virtual_memory().percent,
    disk_percent=psutil.disk_usage('/').percent
)
```

**M√©tricas de Trading:**
```python
# Win rate, P&L, Sharpe
logger.info(
    "Daily trading summary",
    date=date.today(),
    symbol="BTCUSDT",
    trades=15,
    wins=9,
    losses=6,
    win_rate=0.60,
    total_pnl=45.30,
    sharpe_ratio=2.1
)
```

**Performance de Modelos:**
```python
# Detec√ß√£o de drift
logger.warning(
    "Model drift detected",
    model="lgbm_aggressive",
    backtest_win_rate=0.58,
    live_win_rate=0.51,
    drift=0.07  # 7% de degrada√ß√£o
)
```

**Custos de Cloud:**
```python
# Azure + GCP spending
logger.info(
    "Cloud costs",
    date=date.today(),
    azure_cost_usd=12.50,
    gcp_cost_usd=35.80,
    total_cost_usd=48.30,
    budget_remaining_usd=1221.70
)
```

---

### Alertas

**Integra√ß√£o Slack/Telegram:**

```python
import requests

def send_alert(message, level="INFO"):
    """Enviar alerta para Telegram"""
    telegram_token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")

    emoji = {
        "INFO": "‚ÑπÔ∏è",
        "WARNING": "‚ö†Ô∏è",
        "ERROR": "‚ùå",
        "CRITICAL": "üö®"
    }

    text = f"{emoji[level]} {message}"

    requests.post(
        f"https://api.telegram.org/bot{telegram_token}/sendMessage",
        json={"chat_id": chat_id, "text": text}
    )

# Uso
if daily_loss > 5:
    send_alert(
        f"CRITICAL: Perda di√°ria {daily_loss}% excede limite!",
        level="CRITICAL"
    )
```

**Condi√ß√µes de Alerta:**

```yaml
CRITICAL (a√ß√£o imediata):
  - Perda di√°ria > 5%
  - Trading parado (qualquer motivo)
  - Custos cloud > or√ßamento
  - Falha de autentica√ß√£o API

ERROR (corrigir em horas):
  - Treinamento de modelo falhou
  - Erro no pipeline de dados
  - Coleta de orderbook parou
  - Win rate < 50% por 3 dias

WARNING (monitorar):
  - Alta lat√™ncia API (>1s)
  - Drift de modelo > 5%
  - Volume/volatilidade incomum
  - Custos cloud > 80% or√ßamento

INFO (resumo di√°rio):
  - Relat√≥rio P&L di√°rio
  - Resumo de performance dos modelos
  - Resumo de custos cloud
```

---

## üìä Dashboard (Futuro)

**Dashboard Grafana:**

```yaml
Pain√©is:
  - P&L em tempo real (gr√°fico de linha)
  - Win rate por s√≠mbolo (gr√°fico de barras)
  - Posi√ß√µes abertas (tabela)
  - Custos cloud (√°rea empilhada)
  - Drift de modelos (heatmap)
  - Lat√™ncia API (gauge)
  - Recursos do sistema (CPU/Mem√≥ria)

Refresh: A cada 10 segundos
Time range: √öltimas 24 horas (configur√°vel)
```

**Fonte de m√©tricas:**
- TimescaleDB (trades, predi√ß√µes)
- Prometheus (m√©tricas de sistema)
- Elasticsearch (agrega√ß√µes de logs)

---

## üõ†Ô∏è Prioridade de Implementa√ß√£o

### Fase 1 (Imediato - Atual)
- ‚úÖ Armazenamento baseado em arquivos (CSV/Parquet)
- ‚úÖ Logging b√°sico (print/logging)
- ‚úÖ Monitoramento manual

### Fase 2 (Ap√≥s teste orderflow - Jan)
- [ ] Logging estruturado (Loguru)
- [ ] Rota√ß√£o de logs + reten√ß√£o
- [ ] Alertas Telegram (eventos cr√≠ticos)
- [ ] Rastreamento b√°sico de m√©tricas (win rate, P&L)

### Fase 3 (Escala - Fev/Mar)
- [ ] Migra√ß√£o TimescaleDB
- [ ] Setup ELK stack
- [ ] Dashboard Grafana
- [ ] Alertas automatizados (todos os n√≠veis)

### Fase 4 (Produ√ß√£o - Q2)
- [ ] Replica√ß√£o multi-regi√£o
- [ ] Monitoramento avan√ßado (APM)
- [ ] Automa√ß√£o de otimiza√ß√£o de custos
- [ ] Logging de compliance (audit trail)

---

## üí∞ Estimativas de Custo

**ELK Stack (Self-hosted):**
```
VM AWS/Azure: t3.medium (2 vCPU, 4GB RAM)
  Custo: ~$30/m√™s
  Storage: 100GB SSD (~$10/m√™s)
  Total: ~$40/m√™s

Alternativa: Elastic Cloud
  Tier padr√£o: ~$95/m√™s
  Gerenciado, sem overhead de ops
```

**TimescaleDB:**
```
Self-hosted (mesma VM do ELK):
  Custo incremental: ~$5/m√™s (s√≥ storage)

Gerenciado (Timescale Cloud):
  Tier starter: $50/m√™s
  Inclui backups, HA
```

**Custo Mensal Total (Stack Completo):**
```
Self-hosted: ~$45/m√™s
Gerenciado: ~$145/m√™s

Economia vs gerenciado: $100/m√™s (70%)
Tradeoff: Precisa gerenciar infraestrutura
```

---

## üìù Checklist de Migra√ß√£o

**Estrutura de Dados:**
- [ ] Design da nova estrutura de pastas
- [ ] Escrever script de migra√ß√£o
- [ ] Testar com dados de amostra
- [ ] Atualizar todos os scripts (download ‚Üí signals)
- [ ] Atualizar configs
- [ ] Backup da estrutura antiga
- [ ] Executar migra√ß√£o
- [ ] Validar integridade dos dados
- [ ] Atualizar documenta√ß√£o

**Banco de Dados:**
- [ ] Instalar TimescaleDB (local ou cloud)
- [ ] Design do schema
- [ ] Escrever scripts de ingest√£o de dados
- [ ] Escrita dupla (CSV + DB) por 1 semana
- [ ] Testar performance de queries
- [ ] Mudar leituras para DB
- [ ] Depreciar escritas CSV
- [ ] Arquivar CSVs antigos

**Logging:**
- [ ] Instalar Loguru
- [ ] Refatorar print ‚Üí logger
- [ ] Adicionar campos estruturados
- [ ] Configurar rota√ß√£o de logs
- [ ] Setup de alertas Telegram
- [ ] (Opcional) Setup ELK stack
- [ ] Criar dashboards Kibana

---

## üéØ Crit√©rios de Sucesso

**Estrutura de Dados:**
- ‚úÖ Modelos organizados por: symbol/freq/variant/algo/label
- ‚úÖ Separa√ß√£o clara: data vs models
- ‚úÖ Metadata + m√©tricas com cada modelo
- ‚úÖ F√°cil comparar entre s√≠mbolos/variantes

**Banco de Dados:**
- ‚úÖ Resposta de query < 100ms para dados recentes
- ‚úÖ Suportar 1M+ linhas por s√≠mbolo
- ‚úÖ Taxa de compress√£o > 50%
- ‚úÖ Zero perda de dados durante migra√ß√£o

**Logging:**
- ‚úÖ Logs estruturados (JSON)
- ‚úÖ Busc√°vel em <1 segundo
- ‚úÖ Alertas entregues < 30 segundos
- ‚úÖ 99.9% entrega de logs (sem drops)
- ‚úÖ Audit trail claro (quem/o qu√™/quando)

---

**Status do Documento:** Planejamento
**√öltima Atualiza√ß√£o:** 2025-12-10
**Pr√≥xima Revis√£o:** Ap√≥s teste orderflow (2025-12-17)
