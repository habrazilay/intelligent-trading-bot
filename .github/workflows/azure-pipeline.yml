name: Azure ML Pipeline - Training & Deployment

on:
  push:
    branches:
      - main
      - staging
      - dev
  pull_request:
    branches:
      - main
      - staging
  workflow_dispatch:
    inputs:
      config_file:
        description: 'Config file to use (e.g., configs/btcusdt_1m_dev.jsonc)'
        required: false
        default: 'configs/btcusdt_1m_dev.jsonc'
      pipeline_mode:
        description: 'Pipeline mode'
        required: true
        type: choice
        options:
          - full
          - quick
          - train-only
        default: 'quick'

env:
  PYTHON_VERSION: '3.10'
  AZURE_REGION: 'eastus'

jobs:
  # ============================================================================
  # JOB 1: Valida√ß√£o e Testes
  # ============================================================================
  validate:
    name: Validate Code & Dependencies
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate Python syntax
        run: |
          python -m py_compile scripts/*.py
          python -m py_compile service/*.py
          python -m py_compile common/*.py

      - name: Run linter (optional)
        continue-on-error: true
        run: |
          pip install flake8
          flake8 scripts/ --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Verify config files
        run: |
          python -c "
          import json
          from pathlib import Path

          configs = list(Path('configs').glob('*.jsonc'))
          print(f'Found {len(configs)} config files')

          for config in configs:
              print(f'Validating {config.name}...')
              # JSONC validation would go here
          "

  # ============================================================================
  # JOB 2: Download & Prepare Data
  # ============================================================================
  download-data:
    name: Download Historical Data
    runs-on: ubuntu-latest
    needs: validate
    if: ${{ github.event_name == 'workflow_dispatch' || contains(github.event.head_commit.message, '[download]') }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Configure Binance API
        env:
          BINANCE_API_KEY: ${{ secrets.BINANCE_API_KEY }}
          BINANCE_API_SECRET: ${{ secrets.BINANCE_API_SECRET }}
        run: |
          echo "BINANCE_API_KEY=${BINANCE_API_KEY}" >> .env
          echo "BINANCE_API_SECRET=${BINANCE_API_SECRET}" >> .env

      - name: Download Binance data
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"
          python -m scripts.download_binance -c "$CONFIG_FILE"

      - name: Upload data artifacts
        uses: actions/upload-artifact@v4
        with:
          name: raw-data
          path: |
            DATA_ITB_*/*/klines.parquet
          retention-days: 7

  # ============================================================================
  # JOB 3: Feature Engineering Pipeline
  # ============================================================================
  feature-engineering:
    name: Merge & Feature Engineering
    runs-on: ubuntu-latest
    needs: download-data
    if: ${{ always() && (needs.download-data.result == 'success' || needs.download-data.result == 'skipped') }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Download data artifacts
        if: needs.download-data.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: raw-data

      - name: Merge data sources
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"

          # Dry-run primeiro para validar
          python -m scripts.merge_new -c "$CONFIG_FILE" --dry-run

          # Executar de verdade
          python -m scripts.merge_new -c "$CONFIG_FILE"

      - name: Generate features
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"

          # Dry-run
          python -m scripts.features_new -c "$CONFIG_FILE" --dry-run

          # Real
          python -m scripts.features_new -c "$CONFIG_FILE"

      - name: Generate labels
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"

          # Dry-run
          python -m scripts.labels_new -c "$CONFIG_FILE" --dry-run

          # Real
          python -m scripts.labels_new -c "$CONFIG_FILE"

      - name: Upload feature artifacts
        uses: actions/upload-artifact@v4
        with:
          name: features-and-labels
          path: |
            DATA_ITB_*/*/features.csv
            DATA_ITB_*/*/matrix.csv
            DATA_ITB_*/*/features.txt
            DATA_ITB_*/*/matrix.labels.txt
          retention-days: 7

  # ============================================================================
  # JOB 4: Model Training
  # ============================================================================
  train-models:
    name: Train ML Models
    runs-on: ubuntu-latest
    needs: feature-engineering

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Download feature artifacts
        uses: actions/download-artifact@v4
        with:
          name: features-and-labels

      - name: Train models
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"
          python -m scripts.train -c "$CONFIG_FILE"

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-models
          path: |
            MODELS_*/**/*.pkl
            MODELS_*/**/*.joblib
            prediction-metrics.txt
          retention-days: 30

      - name: Upload training metrics
        uses: actions/upload-artifact@v4
        with:
          name: training-metrics
          path: |
            prediction-metrics.txt
            logs/*.log
          retention-days: 30

  # ============================================================================
  # JOB 5: Model Validation & Testing
  # ============================================================================
  validate-models:
    name: Validate Trained Models
    runs-on: ubuntu-latest
    needs: train-models

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models

      - name: Download features
        uses: actions/download-artifact@v4
        with:
          name: features-and-labels

      - name: Run predictions
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"
          python -m scripts.predict -c "$CONFIG_FILE"

      - name: Generate signals
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/btcusdt_1m_dev.jsonc' }}"
          python -m scripts.signals -c "$CONFIG_FILE"

      - name: Validate model performance
        run: |
          python -c "
          from pathlib import Path

          metrics_file = Path('prediction-metrics.txt')
          if metrics_file.exists():
              with open(metrics_file) as f:
                  content = f.read()
                  print('=== Training Metrics ===')
                  print(content)

                  # Basic validation
                  if 'accuracy' in content.lower() or 'score' in content.lower():
                      print('‚úì Metrics file looks valid')
                  else:
                      print('‚ö† Metrics file may be incomplete')
          else:
              print('‚ö† No metrics file found')
              exit(1)
          "

  # ============================================================================
  # JOB 6: Deploy to Azure (Production only)
  # ============================================================================
  deploy-azure:
    name: Deploy to Azure
    runs-on: ubuntu-latest
    needs: validate-models
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    ## environment: prod

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models
          path: ./models

      - name: Upload models to Azure Blob Storage
        run: |
          az storage blob upload-batch \
            --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
            --destination models \
            --source ./models \
            --overwrite

      - name: Deploy Azure ML Endpoint (optional)
        if: false  # Enable when ready
        run: |
          # Configure Azure ML deployment
          echo "Deploying to Azure ML..."
          # az ml endpoint create ...

      - name: Create deployment summary
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Models deployed to Azure Storage" >> $GITHUB_STEP_SUMMARY
          echo "üì¶ Artifacts: $(find ./models -type f | wc -l) files" >> $GITHUB_STEP_SUMMARY
          echo "üîó Storage Account: ${{ secrets.AZURE_STORAGE_ACCOUNT }}" >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # JOB 7: Notification (Success/Failure)
  # ============================================================================
  notify:
    name: Send Notification
    runs-on: ubuntu-latest
    needs: [validate, train-models, validate-models]
    if: always()

    steps:
      - name: Telegram notification (Success)
        if: ${{ needs.validate-models.result == 'success' }}
        run: |
          curl -X POST \
            "https://api.telegram.org/bot${{ secrets.TELEGRAM_BOT_TOKEN }}/sendMessage" \
            -d chat_id="${{ secrets.TELEGRAM_CHAT_ID }}" \
            -d text="‚úÖ Pipeline completed successfully!%0A%0ACommit: ${{ github.sha }}%0ABranch: ${{ github.ref_name }}%0AWorkflow: ${{ github.workflow }}"

      - name: Telegram notification (Failure)
        if: ${{ needs.validate-models.result == 'failure' || needs.train-models.result == 'failure' }}
        run: |
          curl -X POST \
            "https://api.telegram.org/bot${{ secrets.TELEGRAM_BOT_TOKEN }}/sendMessage" \
            -d chat_id="${{ secrets.TELEGRAM_CHAT_ID }}" \
            -d text="‚ùå Pipeline failed!%0A%0ACommit: ${{ github.sha }}%0ABranch: ${{ github.ref_name }}%0ACheck: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
